{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df = pd.read_csv('train/training.csv')\n",
    "training_df = training_df[training_df['last'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = training_df.drop('last', axis=1)\n",
    "train_x.drop(columns=['Unnamed: 0'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = training_df['last']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train_y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(467,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_x.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('test/testing.csv')\n",
    "test_df = test_df[test_df['last'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.drop(columns=['Unnamed: 0'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = test_df['last'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a discretized state vector for each 25 cent increment\n",
    "# array positions (>=.75, .5-.75,.25-.5,0-.25, -.25-0, -.5--.25, -.75 - -.5, <= -.75)\n",
    "def convert_to_vec(listy):\n",
    "    ret_list = np.ndarray((len(listy), 8))\n",
    "    for i, y in enumerate(listy):\n",
    "        if y > 0:\n",
    "            if y <= 0.25:\n",
    "                ret_list[i] = np.array([0,0,0,1,0,0,0,0])\n",
    "            elif y <= 0.5:\n",
    "                ret_list[i] = np.array([0,0,1,0,0,0,0,0])\n",
    "            elif y < 0.75:\n",
    "                ret_list[i] = np.array([0,1,0,0,0,0,0,0])\n",
    "            else:\n",
    "                ret_list[i] = np.array([1,0,0,0,0,0,0,0])\n",
    "        else:\n",
    "            if y >= -0.25:\n",
    "                ret_list[i] = np.array([0,0,0,0,1,0,0,0])\n",
    "            elif y >= -0.5:\n",
    "                ret_list[i] = np.array([0,0,0,0,0,1,0,0])\n",
    "            elif y > -0.75:\n",
    "                ret_list[i] = np.array([0,0,0,0,0,0,1,0])\n",
    "            else:\n",
    "                ret_list[i] = np.array([0,0,0,0,0,0,0,1])\n",
    "    return ret_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = convert_to_vec(test_y)\n",
    "train_y = convert_to_vec(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = test_df.drop(columns=['last']).to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have cleaned NP arrays for our training and testing inputs and outputs, so we begin constructing a Keras model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " hidden1 (Dense)             (None, 12)                252       \n",
      "                                                                 \n",
      " hidden2 (Dense)             (None, 12)                156       \n",
      "                                                                 \n",
      " output (Dense)              (None, 8)                 104       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 512\n",
      "Trainable params: 512\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.Input(shape=(20,)))\n",
    "model.add(layers.Dense(12, name=\"hidden1\", activation='relu')) \n",
    "model.add(layers.Dense(12, name='hidden2', activation='relu'))\n",
    "model.add(layers.Dense(8, name=\"output\", activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.utils.plot_model(\n",
    "    model,\n",
    "    to_file=\"model2.png\",\n",
    "    show_shapes=True,\n",
    "    show_dtype=False,\n",
    "    show_layer_names=True,\n",
    "    rankdir=\"TB\",\n",
    "    expand_nested=False,\n",
    "    dpi=96,\n",
    "    layer_range=None,\n",
    "    show_layer_activations=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reserve ~10% for inter-epoch validation\n",
    "val_x = train_x[-50:]\n",
    "val_y = train_y[-50:]\n",
    "train_x = train_x[:-50]\n",
    "train_y = train_y[:-50]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.SGD(), # stoch grad descent\n",
    "    loss=keras.losses.MeanSquaredError(), # MSE loss function to minimize\n",
    "    metrics=[keras.metrics.Accuracy()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "17/17 [==============================] - 1s 9ms/step - loss: 0.1115 - accuracy: 0.0000e+00 - val_loss: 0.1114 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1114 - accuracy: 0.0000e+00 - val_loss: 0.1113 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1114 - accuracy: 0.0000e+00 - val_loss: 0.1112 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1113 - accuracy: 0.0000e+00 - val_loss: 0.1111 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1112 - accuracy: 0.0000e+00 - val_loss: 0.1111 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1111 - accuracy: 0.0000e+00 - val_loss: 0.1110 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1111 - accuracy: 0.0000e+00 - val_loss: 0.1109 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1110 - accuracy: 0.0000e+00 - val_loss: 0.1108 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1109 - accuracy: 0.0000e+00 - val_loss: 0.1107 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1108 - accuracy: 0.0000e+00 - val_loss: 0.1106 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1108 - accuracy: 0.0000e+00 - val_loss: 0.1106 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1107 - accuracy: 0.0000e+00 - val_loss: 0.1105 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1106 - accuracy: 0.0000e+00 - val_loss: 0.1104 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1105 - accuracy: 0.0000e+00 - val_loss: 0.1103 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1105 - accuracy: 0.0000e+00 - val_loss: 0.1102 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1104 - accuracy: 0.0000e+00 - val_loss: 0.1102 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1103 - accuracy: 0.0000e+00 - val_loss: 0.1101 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1102 - accuracy: 0.0000e+00 - val_loss: 0.1100 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1102 - accuracy: 0.0000e+00 - val_loss: 0.1099 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1101 - accuracy: 0.0000e+00 - val_loss: 0.1099 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1100 - accuracy: 0.0000e+00 - val_loss: 0.1098 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1100 - accuracy: 0.0000e+00 - val_loss: 0.1097 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1099 - accuracy: 0.0000e+00 - val_loss: 0.1096 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1098 - accuracy: 0.0000e+00 - val_loss: 0.1096 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1097 - accuracy: 0.0000e+00 - val_loss: 0.1095 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1097 - accuracy: 0.0000e+00 - val_loss: 0.1094 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1096 - accuracy: 0.0000e+00 - val_loss: 0.1093 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1095 - accuracy: 0.0000e+00 - val_loss: 0.1093 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1095 - accuracy: 0.0000e+00 - val_loss: 0.1092 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1094 - accuracy: 0.0000e+00 - val_loss: 0.1091 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1093 - accuracy: 0.0000e+00 - val_loss: 0.1090 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1093 - accuracy: 0.0000e+00 - val_loss: 0.1090 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1092 - accuracy: 0.0000e+00 - val_loss: 0.1089 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1091 - accuracy: 0.0000e+00 - val_loss: 0.1088 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1091 - accuracy: 0.0000e+00 - val_loss: 0.1087 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1090 - accuracy: 0.0000e+00 - val_loss: 0.1087 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1089 - accuracy: 0.0000e+00 - val_loss: 0.1086 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 0.1089 - accuracy: 0.0000e+00 - val_loss: 0.1085 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1088 - accuracy: 0.0000e+00 - val_loss: 0.1084 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1087 - accuracy: 0.0000e+00 - val_loss: 0.1084 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1087 - accuracy: 0.0000e+00 - val_loss: 0.1083 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1086 - accuracy: 0.0000e+00 - val_loss: 0.1082 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1085 - accuracy: 0.0000e+00 - val_loss: 0.1082 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1085 - accuracy: 0.0000e+00 - val_loss: 0.1081 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1084 - accuracy: 0.0000e+00 - val_loss: 0.1080 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1083 - accuracy: 0.0000e+00 - val_loss: 0.1079 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1083 - accuracy: 0.0000e+00 - val_loss: 0.1079 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1082 - accuracy: 0.0000e+00 - val_loss: 0.1078 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1081 - accuracy: 0.0000e+00 - val_loss: 0.1077 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1081 - accuracy: 0.0000e+00 - val_loss: 0.1077 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1080 - accuracy: 0.0000e+00 - val_loss: 0.1076 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1079 - accuracy: 0.0000e+00 - val_loss: 0.1075 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1079 - accuracy: 0.0000e+00 - val_loss: 0.1074 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1078 - accuracy: 0.0000e+00 - val_loss: 0.1074 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1077 - accuracy: 0.0000e+00 - val_loss: 0.1073 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1077 - accuracy: 0.0000e+00 - val_loss: 0.1072 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1076 - accuracy: 0.0000e+00 - val_loss: 0.1072 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1075 - accuracy: 0.0000e+00 - val_loss: 0.1071 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1075 - accuracy: 0.0000e+00 - val_loss: 0.1070 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1074 - accuracy: 0.0000e+00 - val_loss: 0.1070 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1073 - accuracy: 0.0000e+00 - val_loss: 0.1069 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1073 - accuracy: 0.0000e+00 - val_loss: 0.1068 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1072 - accuracy: 0.0000e+00 - val_loss: 0.1067 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1071 - accuracy: 0.0000e+00 - val_loss: 0.1067 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1071 - accuracy: 0.0000e+00 - val_loss: 0.1066 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1070 - accuracy: 0.0000e+00 - val_loss: 0.1065 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1069 - accuracy: 0.0000e+00 - val_loss: 0.1065 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1069 - accuracy: 0.0000e+00 - val_loss: 0.1064 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1068 - accuracy: 0.0000e+00 - val_loss: 0.1063 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1067 - accuracy: 0.0000e+00 - val_loss: 0.1062 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1067 - accuracy: 0.0000e+00 - val_loss: 0.1062 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1066 - accuracy: 0.0000e+00 - val_loss: 0.1061 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1065 - accuracy: 0.0000e+00 - val_loss: 0.1060 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1065 - accuracy: 0.0000e+00 - val_loss: 0.1059 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1064 - accuracy: 0.0000e+00 - val_loss: 0.1059 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1063 - accuracy: 0.0000e+00 - val_loss: 0.1058 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1063 - accuracy: 0.0000e+00 - val_loss: 0.1057 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1062 - accuracy: 0.0000e+00 - val_loss: 0.1056 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1061 - accuracy: 0.0000e+00 - val_loss: 0.1056 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1061 - accuracy: 0.0000e+00 - val_loss: 0.1055 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1060 - accuracy: 0.0000e+00 - val_loss: 0.1054 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1059 - accuracy: 0.0000e+00 - val_loss: 0.1053 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1059 - accuracy: 0.0000e+00 - val_loss: 0.1053 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1058 - accuracy: 0.0000e+00 - val_loss: 0.1052 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1057 - accuracy: 0.0000e+00 - val_loss: 0.1051 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1057 - accuracy: 0.0000e+00 - val_loss: 0.1050 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1056 - accuracy: 0.0000e+00 - val_loss: 0.1050 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1055 - accuracy: 0.0000e+00 - val_loss: 0.1049 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1055 - accuracy: 0.0000e+00 - val_loss: 0.1048 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1054 - accuracy: 0.0000e+00 - val_loss: 0.1047 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1053 - accuracy: 0.0000e+00 - val_loss: 0.1047 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1053 - accuracy: 0.0000e+00 - val_loss: 0.1046 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1052 - accuracy: 0.0000e+00 - val_loss: 0.1045 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1051 - accuracy: 0.0000e+00 - val_loss: 0.1044 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1050 - accuracy: 0.0000e+00 - val_loss: 0.1044 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1050 - accuracy: 0.0000e+00 - val_loss: 0.1043 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1049 - accuracy: 0.0000e+00 - val_loss: 0.1042 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1048 - accuracy: 0.0000e+00 - val_loss: 0.1041 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1048 - accuracy: 0.0000e+00 - val_loss: 0.1041 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 0.1047 - accuracy: 0.0000e+00 - val_loss: 0.1040 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "session = model.fit(\n",
    "    train_x,\n",
    "    train_y,\n",
    "    batch_size=25,\n",
    "    epochs=100, \n",
    "    validation_data=(val_x, val_y),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.11075419187545776,\n",
       "  0.11068885028362274,\n",
       "  0.11062321811914444,\n",
       "  0.11055806279182434,\n",
       "  0.11049234867095947,\n",
       "  0.11042656004428864,\n",
       "  0.11036078631877899,\n",
       "  0.11029519885778427,\n",
       "  0.11022946238517761,\n",
       "  0.11016343533992767,\n",
       "  0.11009759455919266,\n",
       "  0.11003189533948898,\n",
       "  0.10996607691049576,\n",
       "  0.10990050435066223,\n",
       "  0.10983487963676453,\n",
       "  0.10976909101009369,\n",
       "  0.10970330238342285,\n",
       "  0.10963735729455948,\n",
       "  0.10957162827253342,\n",
       "  0.10950559377670288,\n",
       "  0.1094399020075798,\n",
       "  0.1093740239739418,\n",
       "  0.10930798947811127,\n",
       "  0.10924192517995834,\n",
       "  0.10917571187019348,\n",
       "  0.10910982638597488,\n",
       "  0.10904323309659958,\n",
       "  0.10897686332464218,\n",
       "  0.10891064256429672,\n",
       "  0.10884419083595276,\n",
       "  0.10877762734889984,\n",
       "  0.1087111085653305,\n",
       "  0.10864494740962982,\n",
       "  0.1085783988237381,\n",
       "  0.10851187258958817,\n",
       "  0.1084451749920845,\n",
       "  0.10837839543819427,\n",
       "  0.10831192880868912,\n",
       "  0.1082456037402153,\n",
       "  0.10817880183458328,\n",
       "  0.10811228305101395,\n",
       "  0.10804573446512222,\n",
       "  0.10797885805368423,\n",
       "  0.10791237652301788,\n",
       "  0.10784570127725601,\n",
       "  0.10777907818555832,\n",
       "  0.10771247744560242,\n",
       "  0.1076456680893898,\n",
       "  0.1075788363814354,\n",
       "  0.10751186311244965,\n",
       "  0.10744485259056091,\n",
       "  0.10737767815589905,\n",
       "  0.10731103271245956,\n",
       "  0.10724415630102158,\n",
       "  0.10717694461345673,\n",
       "  0.10711027681827545,\n",
       "  0.1070437878370285,\n",
       "  0.10697652399539948,\n",
       "  0.10690931230783463,\n",
       "  0.10684201121330261,\n",
       "  0.10677476972341537,\n",
       "  0.10670772939920425,\n",
       "  0.10664056986570358,\n",
       "  0.1065732017159462,\n",
       "  0.10650596022605896,\n",
       "  0.10643835365772247,\n",
       "  0.10637082904577255,\n",
       "  0.10630305856466293,\n",
       "  0.10623591393232346,\n",
       "  0.10616796463727951,\n",
       "  0.10610061883926392,\n",
       "  0.10603293776512146,\n",
       "  0.1059655025601387,\n",
       "  0.10589788854122162,\n",
       "  0.10583021491765976,\n",
       "  0.10576269775629044,\n",
       "  0.10569506883621216,\n",
       "  0.1056271567940712,\n",
       "  0.1055593341588974,\n",
       "  0.10549164563417435,\n",
       "  0.10542358458042145,\n",
       "  0.10535618662834167,\n",
       "  0.10528804361820221,\n",
       "  0.1052202358841896,\n",
       "  0.1051524206995964,\n",
       "  0.10508446395397186,\n",
       "  0.10501649230718613,\n",
       "  0.10494887083768845,\n",
       "  0.10488057136535645,\n",
       "  0.1048123687505722,\n",
       "  0.10474403947591782,\n",
       "  0.10467521846294403,\n",
       "  0.1046065092086792,\n",
       "  0.10453792661428452,\n",
       "  0.10446884483098984,\n",
       "  0.10440051555633545,\n",
       "  0.10433152318000793,\n",
       "  0.10426231473684311,\n",
       "  0.10419341176748276,\n",
       "  0.1041242778301239],\n",
       " 'accuracy': [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " 'val_loss': [0.10969798266887665,\n",
       "  0.10962837189435959,\n",
       "  0.10955939441919327,\n",
       "  0.10948991775512695,\n",
       "  0.10942022502422333,\n",
       "  0.1093507930636406,\n",
       "  0.10928139090538025,\n",
       "  0.10921203345060349,\n",
       "  0.10914210975170135,\n",
       "  0.10907203704118729,\n",
       "  0.10900209099054337,\n",
       "  0.10893195867538452,\n",
       "  0.10886167734861374,\n",
       "  0.10879158228635788,\n",
       "  0.10872133076190948,\n",
       "  0.10865096747875214,\n",
       "  0.10858038812875748,\n",
       "  0.1085100769996643,\n",
       "  0.10843952000141144,\n",
       "  0.10836923867464066,\n",
       "  0.1082983985543251,\n",
       "  0.10822758823633194,\n",
       "  0.10815681517124176,\n",
       "  0.1080860123038292,\n",
       "  0.10801573097705841,\n",
       "  0.10794445127248764,\n",
       "  0.10787346214056015,\n",
       "  0.10780248790979385,\n",
       "  0.10773114114999771,\n",
       "  0.10765977948904037,\n",
       "  0.10758852958679199,\n",
       "  0.10751762241125107,\n",
       "  0.10744623839855194,\n",
       "  0.1073746457695961,\n",
       "  0.10730297118425369,\n",
       "  0.10723081231117249,\n",
       "  0.10715900361537933,\n",
       "  0.10708747059106827,\n",
       "  0.10701512545347214,\n",
       "  0.10694320499897003,\n",
       "  0.10687115043401718,\n",
       "  0.10679864883422852,\n",
       "  0.10672685503959656,\n",
       "  0.10665471851825714,\n",
       "  0.10658256709575653,\n",
       "  0.10651027411222458,\n",
       "  0.10643775761127472,\n",
       "  0.10636530071496964,\n",
       "  0.10629290342330933,\n",
       "  0.10622059553861618,\n",
       "  0.10614825040102005,\n",
       "  0.10607632994651794,\n",
       "  0.10600433498620987,\n",
       "  0.10593165457248688,\n",
       "  0.10585958510637283,\n",
       "  0.105787493288517,\n",
       "  0.10571479797363281,\n",
       "  0.10564195364713669,\n",
       "  0.10556871443986893,\n",
       "  0.1054956465959549,\n",
       "  0.10542254149913788,\n",
       "  0.1053493395447731,\n",
       "  0.10527599602937698,\n",
       "  0.10520254075527191,\n",
       "  0.10512921959161758,\n",
       "  0.10505550354719162,\n",
       "  0.10498140007257462,\n",
       "  0.1049080565571785,\n",
       "  0.10483400523662567,\n",
       "  0.10476037859916687,\n",
       "  0.10468650609254837,\n",
       "  0.1046125590801239,\n",
       "  0.10453858971595764,\n",
       "  0.1044645681977272,\n",
       "  0.10439042001962662,\n",
       "  0.1043168231844902,\n",
       "  0.10424255579710007,\n",
       "  0.10416862368583679,\n",
       "  0.10409475117921829,\n",
       "  0.10402025282382965,\n",
       "  0.10394628345966339,\n",
       "  0.10387157648801804,\n",
       "  0.10379689931869507,\n",
       "  0.10372277349233627,\n",
       "  0.10364778339862823,\n",
       "  0.10357291996479034,\n",
       "  0.10349858552217484,\n",
       "  0.10342326760292053,\n",
       "  0.10334815829992294,\n",
       "  0.10327274352312088,\n",
       "  0.10319656133651733,\n",
       "  0.10312057286500931,\n",
       "  0.10304499417543411,\n",
       "  0.1029692068696022,\n",
       "  0.10289406776428223,\n",
       "  0.10281793773174286,\n",
       "  0.10274196416139603,\n",
       "  0.10266600549221039,\n",
       "  0.10258990526199341,\n",
       "  0.10251374542713165],\n",
       " 'val_accuracy': [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0]}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 2ms/step - loss: 0.1030 - accuracy: 0.0000e+00\n",
      "test loss, test acc: [0.10295502096414566, 0.0]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(test_x, test_y, batch_size=100)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "direction_success = 0\n",
    "for i, pred in enumerate(predictions):\n",
    "    pred_index = np.argmax(pred)\n",
    "    test_index = np.argmax(test_y[i])\n",
    "    if pred_index <= 3  and test_index <= 3:\n",
    "        direction_success += 1\n",
    "    elif pred_index > 3 and test_index > 3:\n",
    "        direction_success += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5149253731343284"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute accuracy of the direction of travel\n",
    "direction_success / len(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute accuracy within one tick (0.25)\n",
    "tick_success = 0\n",
    "for i, pred in enumerate(predictions):\n",
    "    pred_index = np.argmax(pred)\n",
    "    test_index = np.argmax(test_y[i])\n",
    "    if pred_index == test_index:\n",
    "        tick_success += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48134328358208955"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tick_success / len(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee094fbcebf3723d246997847463d458ed3326061a0ee2e7aa600f421b4f224"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
