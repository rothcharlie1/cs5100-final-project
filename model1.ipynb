{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_df = pd.read_csv('train/training.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = training_df.drop('last', axis=1)\n",
    "train_x.drop(columns=['Unnamed: 0'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = training_df['last']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train_y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_x.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('test/testing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.drop(columns=['Unnamed: 0'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = test_df['last'].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = test_df.drop(columns=['last']).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_vec(listy):\n",
    "    ret_list = np.ndarray((len(listy), 8))\n",
    "    for i, y in enumerate(listy):\n",
    "        if y > 0:\n",
    "            if y <= 0.25:\n",
    "                ret_list[i] = np.array([0,0,0,1,0,0,0,0])\n",
    "            elif y <= 0.5:\n",
    "                ret_list[i] = np.array([0,0,1,0,0,0,0,0])\n",
    "            elif y < 0.75:\n",
    "                ret_list[i] = np.array([0,1,0,0,0,0,0,0])\n",
    "            else:\n",
    "                ret_list[i] = np.array([1,0,0,0,0,0,0,0])\n",
    "        else:\n",
    "            if y >= -0.25:\n",
    "                ret_list[i] = np.array([0,0,0,0,1,0,0,0])\n",
    "            elif y >= -0.5:\n",
    "                ret_list[i] = np.array([0,0,0,0,0,1,0,0])\n",
    "            elif y > -0.75:\n",
    "                ret_list[i] = np.array([0,0,0,0,0,0,1,0])\n",
    "            else:\n",
    "                ret_list[i] = np.array([0,0,0,0,0,0,0,1])\n",
    "    return ret_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = convert_to_vec(test_y)\n",
    "train_y = convert_to_vec(train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have cleaned NP arrays for our training and testing inputs and outputs, so we begin constructing a Keras model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " hidden1 (Dense)             (None, 5)                 105       \n",
      "                                                                 \n",
      " output (Dense)              (None, 8)                 48        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 153\n",
      "Trainable params: 153\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.Input(shape=(20,)))\n",
    "model.add(layers.Dense(5, name=\"hidden1\")) \n",
    "model.add(layers.Dense(8, name=\"output\"))\n",
    "\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.utils.plot_model(\n",
    "    model,\n",
    "    to_file=\"model1.png\",\n",
    "    show_shapes=True,\n",
    "    show_dtype=False,\n",
    "    show_layer_names=True,\n",
    "    rankdir=\"TB\",\n",
    "    expand_nested=False,\n",
    "    dpi=96,\n",
    "    layer_range=None,\n",
    "    show_layer_activations=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reserve ~10% for inter-epoch validation\n",
    "val_x = train_x[-200:]\n",
    "val_y = train_y[-200:]\n",
    "train_x = train_x[:-200]\n",
    "train_y = train_y[:-200]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.SGD(), # stoch grad descent\n",
    "    loss=keras.losses.MeanSquaredError(), # MSE loss function to minimize\n",
    "    metrics=[keras.metrics.Accuracy()],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "46/46 [==============================] - 0s 4ms/step - loss: 0.1332 - accuracy: 0.0019 - val_loss: 0.1208 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.1087 - accuracy: 0.0000e+00 - val_loss: 0.1006 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0926 - accuracy: 0.0000e+00 - val_loss: 0.0865 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0814 - accuracy: 0.0000e+00 - val_loss: 0.0765 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0733 - accuracy: 0.0000e+00 - val_loss: 0.0692 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0675 - accuracy: 0.0000e+00 - val_loss: 0.0636 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0630 - accuracy: 0.0000e+00 - val_loss: 0.0592 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0595 - accuracy: 0.0000e+00 - val_loss: 0.0557 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0567 - accuracy: 0.0000e+00 - val_loss: 0.0530 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.0545 - accuracy: 0.0000e+00 - val_loss: 0.0508 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0528 - accuracy: 0.0000e+00 - val_loss: 0.0490 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0514 - accuracy: 0.0000e+00 - val_loss: 0.0476 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0503 - accuracy: 0.0000e+00 - val_loss: 0.0464 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0493 - accuracy: 0.0000e+00 - val_loss: 0.0454 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0486 - accuracy: 0.0000e+00 - val_loss: 0.0445 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0479 - accuracy: 0.0000e+00 - val_loss: 0.0437 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0473 - accuracy: 0.0000e+00 - val_loss: 0.0430 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0468 - accuracy: 0.0000e+00 - val_loss: 0.0425 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.0464 - accuracy: 0.0000e+00 - val_loss: 0.0420 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.0460 - accuracy: 0.0000e+00 - val_loss: 0.0415 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0456 - accuracy: 0.0000e+00 - val_loss: 0.0411 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0453 - accuracy: 0.0000e+00 - val_loss: 0.0407 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0450 - accuracy: 0.0000e+00 - val_loss: 0.0403 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0447 - accuracy: 0.0000e+00 - val_loss: 0.0400 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.0444 - accuracy: 0.0000e+00 - val_loss: 0.0397 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "46/46 [==============================] - 0s 3ms/step - loss: 0.0442 - accuracy: 0.0000e+00 - val_loss: 0.0394 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0439 - accuracy: 0.0000e+00 - val_loss: 0.0391 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0437 - accuracy: 0.0000e+00 - val_loss: 0.0388 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0435 - accuracy: 0.0000e+00 - val_loss: 0.0386 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0433 - accuracy: 0.0000e+00 - val_loss: 0.0383 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0431 - accuracy: 0.0000e+00 - val_loss: 0.0381 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0429 - accuracy: 0.0000e+00 - val_loss: 0.0378 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0427 - accuracy: 0.0000e+00 - val_loss: 0.0376 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0425 - accuracy: 0.0000e+00 - val_loss: 0.0373 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0423 - accuracy: 0.0000e+00 - val_loss: 0.0371 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0421 - accuracy: 0.0000e+00 - val_loss: 0.0369 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0419 - accuracy: 0.0000e+00 - val_loss: 0.0367 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0417 - accuracy: 0.0000e+00 - val_loss: 0.0365 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0416 - accuracy: 0.0000e+00 - val_loss: 0.0363 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0414 - accuracy: 0.0000e+00 - val_loss: 0.0361 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0412 - accuracy: 0.0000e+00 - val_loss: 0.0359 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0411 - accuracy: 0.0000e+00 - val_loss: 0.0357 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0409 - accuracy: 0.0000e+00 - val_loss: 0.0356 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0407 - accuracy: 0.0000e+00 - val_loss: 0.0354 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0406 - accuracy: 0.0000e+00 - val_loss: 0.0352 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0404 - accuracy: 0.0000e+00 - val_loss: 0.0351 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0403 - accuracy: 0.0000e+00 - val_loss: 0.0349 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0401 - accuracy: 0.0000e+00 - val_loss: 0.0347 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0400 - accuracy: 0.0000e+00 - val_loss: 0.0346 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0398 - accuracy: 0.0000e+00 - val_loss: 0.0344 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0397 - accuracy: 0.0000e+00 - val_loss: 0.0343 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0396 - accuracy: 0.0000e+00 - val_loss: 0.0341 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0394 - accuracy: 0.0000e+00 - val_loss: 0.0339 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0393 - accuracy: 0.0000e+00 - val_loss: 0.0338 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0392 - accuracy: 0.0000e+00 - val_loss: 0.0336 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0391 - accuracy: 0.0000e+00 - val_loss: 0.0335 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0389 - accuracy: 0.0000e+00 - val_loss: 0.0333 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0388 - accuracy: 0.0000e+00 - val_loss: 0.0332 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0387 - accuracy: 0.0000e+00 - val_loss: 0.0330 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0386 - accuracy: 0.0000e+00 - val_loss: 0.0329 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0384 - accuracy: 0.0000e+00 - val_loss: 0.0328 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0383 - accuracy: 0.0000e+00 - val_loss: 0.0326 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0382 - accuracy: 0.0000e+00 - val_loss: 0.0325 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0381 - accuracy: 0.0000e+00 - val_loss: 0.0324 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0380 - accuracy: 0.0000e+00 - val_loss: 0.0322 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0379 - accuracy: 0.0000e+00 - val_loss: 0.0321 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0378 - accuracy: 0.0000e+00 - val_loss: 0.0320 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0377 - accuracy: 0.0000e+00 - val_loss: 0.0319 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0376 - accuracy: 0.0000e+00 - val_loss: 0.0318 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0375 - accuracy: 0.0000e+00 - val_loss: 0.0316 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0374 - accuracy: 0.0000e+00 - val_loss: 0.0315 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0373 - accuracy: 0.0000e+00 - val_loss: 0.0314 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0372 - accuracy: 0.0000e+00 - val_loss: 0.0313 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0371 - accuracy: 0.0000e+00 - val_loss: 0.0312 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0370 - accuracy: 0.0000e+00 - val_loss: 0.0311 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0369 - accuracy: 0.0000e+00 - val_loss: 0.0310 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0368 - accuracy: 0.0000e+00 - val_loss: 0.0309 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0367 - accuracy: 0.0000e+00 - val_loss: 0.0308 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0366 - accuracy: 0.0000e+00 - val_loss: 0.0307 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0365 - accuracy: 0.0000e+00 - val_loss: 0.0306 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0364 - accuracy: 0.0000e+00 - val_loss: 0.0305 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0363 - accuracy: 0.0000e+00 - val_loss: 0.0304 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0363 - accuracy: 0.0000e+00 - val_loss: 0.0303 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0362 - accuracy: 0.0000e+00 - val_loss: 0.0301 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0361 - accuracy: 0.0000e+00 - val_loss: 0.0300 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0360 - accuracy: 0.0000e+00 - val_loss: 0.0300 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0359 - accuracy: 0.0000e+00 - val_loss: 0.0299 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0358 - accuracy: 0.0000e+00 - val_loss: 0.0298 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0358 - accuracy: 0.0000e+00 - val_loss: 0.0297 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0357 - accuracy: 0.0000e+00 - val_loss: 0.0296 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0356 - accuracy: 0.0000e+00 - val_loss: 0.0295 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0355 - accuracy: 0.0000e+00 - val_loss: 0.0294 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0355 - accuracy: 0.0000e+00 - val_loss: 0.0293 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0354 - accuracy: 0.0000e+00 - val_loss: 0.0292 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0353 - accuracy: 0.0000e+00 - val_loss: 0.0291 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0352 - accuracy: 0.0000e+00 - val_loss: 0.0291 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0352 - accuracy: 0.0000e+00 - val_loss: 0.0290 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0351 - accuracy: 0.0000e+00 - val_loss: 0.0289 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0350 - accuracy: 0.0000e+00 - val_loss: 0.0288 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "46/46 [==============================] - 0s 2ms/step - loss: 0.0350 - accuracy: 0.0000e+00 - val_loss: 0.0287 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "session = model.fit(\n",
    "    train_x,\n",
    "    train_y,\n",
    "    batch_size=50,\n",
    "    epochs=100, \n",
    "    validation_data=(val_x, val_y),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.13322694599628448,\n",
       "  0.10865171253681183,\n",
       "  0.0926128625869751,\n",
       "  0.08138300478458405,\n",
       "  0.07333316653966904,\n",
       "  0.0674690529704094,\n",
       "  0.06303130090236664,\n",
       "  0.05946342647075653,\n",
       "  0.05670314282178879,\n",
       "  0.05452881380915642,\n",
       "  0.05279618129134178,\n",
       "  0.05139712244272232,\n",
       "  0.05030522868037224,\n",
       "  0.049348343163728714,\n",
       "  0.048578549176454544,\n",
       "  0.047901421785354614,\n",
       "  0.04731564223766327,\n",
       "  0.04680653661489487,\n",
       "  0.04636256396770477,\n",
       "  0.04596694931387901,\n",
       "  0.045606594532728195,\n",
       "  0.04529329016804695,\n",
       "  0.04498877376317978,\n",
       "  0.04470237344503403,\n",
       "  0.0444365032017231,\n",
       "  0.04418446496129036,\n",
       "  0.043942641466856,\n",
       "  0.04371146857738495,\n",
       "  0.04349644109606743,\n",
       "  0.04327215626835823,\n",
       "  0.043061863631010056,\n",
       "  0.04285747930407524,\n",
       "  0.04265930503606796,\n",
       "  0.04246652126312256,\n",
       "  0.042278606444597244,\n",
       "  0.042094938457012177,\n",
       "  0.04190656915307045,\n",
       "  0.04173137992620468,\n",
       "  0.04155692830681801,\n",
       "  0.041389595717191696,\n",
       "  0.04122612625360489,\n",
       "  0.041062869131565094,\n",
       "  0.04090452566742897,\n",
       "  0.04074550420045853,\n",
       "  0.04059046134352684,\n",
       "  0.04043816030025482,\n",
       "  0.04028702899813652,\n",
       "  0.04013368487358093,\n",
       "  0.03999108821153641,\n",
       "  0.03984677791595459,\n",
       "  0.039708834141492844,\n",
       "  0.03957295045256615,\n",
       "  0.03943949565291405,\n",
       "  0.039306432008743286,\n",
       "  0.03917758911848068,\n",
       "  0.039050567895174026,\n",
       "  0.038926251232624054,\n",
       "  0.03880389407277107,\n",
       "  0.038680300116539,\n",
       "  0.0385623499751091,\n",
       "  0.03844492509961128,\n",
       "  0.03833017125725746,\n",
       "  0.03821560740470886,\n",
       "  0.0381043516099453,\n",
       "  0.03799402713775635,\n",
       "  0.037885185331106186,\n",
       "  0.03777872398495674,\n",
       "  0.03767407685518265,\n",
       "  0.037566423416137695,\n",
       "  0.037465114146471024,\n",
       "  0.037361301481723785,\n",
       "  0.037262070924043655,\n",
       "  0.03716355189681053,\n",
       "  0.037067294120788574,\n",
       "  0.03697292506694794,\n",
       "  0.03687740117311478,\n",
       "  0.03678566962480545,\n",
       "  0.03669212758541107,\n",
       "  0.036601465195417404,\n",
       "  0.036510661244392395,\n",
       "  0.036426566541194916,\n",
       "  0.03633749857544899,\n",
       "  0.03625102713704109,\n",
       "  0.036167826503515244,\n",
       "  0.03608650714159012,\n",
       "  0.03600488603115082,\n",
       "  0.035925302654504776,\n",
       "  0.0358467660844326,\n",
       "  0.035767409950494766,\n",
       "  0.03569036349654198,\n",
       "  0.03561418503522873,\n",
       "  0.035539206117391586,\n",
       "  0.035464510321617126,\n",
       "  0.03539031744003296,\n",
       "  0.035317596048116684,\n",
       "  0.03524642810225487,\n",
       "  0.035175345838069916,\n",
       "  0.03510577231645584,\n",
       "  0.03503705933690071,\n",
       "  0.03496966511011124],\n",
       " 'accuracy': [0.0019427175866439939,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " 'val_loss': [0.12081678211688995,\n",
       "  0.10055092722177505,\n",
       "  0.08648626506328583,\n",
       "  0.07645031809806824,\n",
       "  0.06916601210832596,\n",
       "  0.06364147365093231,\n",
       "  0.05918201431632042,\n",
       "  0.055718060582876205,\n",
       "  0.05297030508518219,\n",
       "  0.05077877640724182,\n",
       "  0.048984918743371964,\n",
       "  0.04759853333234787,\n",
       "  0.046370137482881546,\n",
       "  0.045375920832157135,\n",
       "  0.04447782039642334,\n",
       "  0.043714918196201324,\n",
       "  0.043046239763498306,\n",
       "  0.042467452585697174,\n",
       "  0.04195621982216835,\n",
       "  0.04150168597698212,\n",
       "  0.04109715297818184,\n",
       "  0.040704745799303055,\n",
       "  0.040330301970243454,\n",
       "  0.03999326378107071,\n",
       "  0.03967979550361633,\n",
       "  0.03938521817326546,\n",
       "  0.039093006402254105,\n",
       "  0.038819435983896255,\n",
       "  0.038560885936021805,\n",
       "  0.03830280900001526,\n",
       "  0.03805197775363922,\n",
       "  0.037814199924468994,\n",
       "  0.037576451897621155,\n",
       "  0.03734360262751579,\n",
       "  0.037134334444999695,\n",
       "  0.03690437227487564,\n",
       "  0.036703869700431824,\n",
       "  0.03649890795350075,\n",
       "  0.03631950542330742,\n",
       "  0.03612559661269188,\n",
       "  0.03593479469418526,\n",
       "  0.03574712574481964,\n",
       "  0.03557581454515457,\n",
       "  0.03541390225291252,\n",
       "  0.03523169830441475,\n",
       "  0.03505319729447365,\n",
       "  0.03489368036389351,\n",
       "  0.03472486883401871,\n",
       "  0.03456726670265198,\n",
       "  0.03439700976014137,\n",
       "  0.03425275906920433,\n",
       "  0.034090008586645126,\n",
       "  0.03394056856632233,\n",
       "  0.033780112862586975,\n",
       "  0.033622656017541885,\n",
       "  0.03346727415919304,\n",
       "  0.033323630690574646,\n",
       "  0.033178601413965225,\n",
       "  0.0330386720597744,\n",
       "  0.03289935365319252,\n",
       "  0.03276228532195091,\n",
       "  0.03263327479362488,\n",
       "  0.032496899366378784,\n",
       "  0.03236831724643707,\n",
       "  0.032237134873867035,\n",
       "  0.03210901841521263,\n",
       "  0.0319814532995224,\n",
       "  0.03187121823430061,\n",
       "  0.031752098351716995,\n",
       "  0.03163357824087143,\n",
       "  0.03151049464941025,\n",
       "  0.03138929232954979,\n",
       "  0.03127575293183327,\n",
       "  0.03116237185895443,\n",
       "  0.031077759340405464,\n",
       "  0.030963020399212837,\n",
       "  0.03087228536605835,\n",
       "  0.030787887051701546,\n",
       "  0.03067430481314659,\n",
       "  0.030602432787418365,\n",
       "  0.03047822415828705,\n",
       "  0.030358774587512016,\n",
       "  0.03025161661207676,\n",
       "  0.030146822333335876,\n",
       "  0.03004596196115017,\n",
       "  0.02996470034122467,\n",
       "  0.029881486669182777,\n",
       "  0.029781347140669823,\n",
       "  0.029676880687475204,\n",
       "  0.02958041988313198,\n",
       "  0.029488421976566315,\n",
       "  0.029394397512078285,\n",
       "  0.029331738129258156,\n",
       "  0.02923518233001232,\n",
       "  0.02913864329457283,\n",
       "  0.02905147336423397,\n",
       "  0.028965143486857414,\n",
       "  0.028879495337605476,\n",
       "  0.028791455551981926,\n",
       "  0.02870701253414154],\n",
       " 'val_accuracy': [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0]}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 1ms/step - loss: 0.0254 - accuracy: 0.0000e+00\n",
      "test loss, test acc: [0.02544104866683483, 0.0]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(test_x, test_y, batch_size=100)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.05307972, -0.14497998, -0.02493191, ...,  0.04999133,\n",
       "        -0.04941657, -0.08710968],\n",
       "       [-0.12842944,  0.02787983, -0.01477003, ...,  0.08148119,\n",
       "        -0.04308541, -0.08866346],\n",
       "       [ 0.00254776,  0.00124564,  0.00693974, ...,  0.01145821,\n",
       "         0.00204576,  0.00608774],\n",
       "       ...,\n",
       "       [ 0.02872169,  0.04641756,  0.0059079 , ...,  0.0156191 ,\n",
       "         0.01581341,  0.02509421],\n",
       "       [ 0.00254776,  0.00124564,  0.00693974, ...,  0.01145821,\n",
       "         0.00204576,  0.00608774],\n",
       "       [-0.0389227 ,  0.00860297,  0.04912595, ...,  0.02779742,\n",
       "        -0.03796467, -0.05499049]], dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model.predict(test_x)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y[700:710]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "direction_success = 0\n",
    "for i, pred in enumerate(predictions):\n",
    "    pred_index = np.argmax(pred)\n",
    "    test_index = np.argmax(test_y[i])\n",
    "    if pred_index <= 3  and test_index <= 3:\n",
    "        direction_success += 1\n",
    "    elif pred_index > 3 and test_index > 3:\n",
    "        direction_success += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9153374233128835"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "direction_success / len(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "tick_success = 0\n",
    "for i, pred in enumerate(predictions):\n",
    "    pred_index = np.argmax(pred)\n",
    "    test_index = np.argmax(test_y[i])\n",
    "    if pred_index == test_index:\n",
    "        tick_success += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.911042944785276"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tick_success / len(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee094fbcebf3723d246997847463d458ed3326061a0ee2e7aa600f421b4f224"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
